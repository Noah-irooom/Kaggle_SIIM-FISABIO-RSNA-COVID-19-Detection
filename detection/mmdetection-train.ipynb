{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Thanks to \n- https://github.com/open-mmlab/mmdetection/blob/master/demo/MMDet_Tutorial.ipynb\n- https://www.kaggle.com/sreevishnudamodaran/siim-effnetv2-l-cascadercnn-mmdetection-infer","metadata":{"id":"zgMM6G4XOhpk"}},{"cell_type":"code","source":"## MMDetection compatible torch installation\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchaudio-0.7.0-cp37-cp37m-linux_x86_64.whl' --no-deps\n\n## Compatible Cuda Toolkit installation\n!mkdir -p /kaggle/tmp && cp /kaggle/input/pytorch-170-cuda-toolkit-110221/cudatoolkit-11.0.221-h6bb024c_0 /kaggle/tmp/cudatoolkit-11.0.221-h6bb024c_0.tar.bz2 && conda install /kaggle/tmp/cudatoolkit-11.0.221-h6bb024c_0.tar.bz2 -y --offline\n\n## MMDetection Offline Installation\n!pip install '/kaggle/input/mmdetectionv2140/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmcv_full-1_3_8-cu110-torch1_7_0/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/pycocotools-2.0.2/pycocotools-2.0.2' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps\n\n!cp -r /kaggle/input/mmdetectionv2140/mmdetection-2.14.0 /kaggle/working/\n!mv /kaggle/working/mmdetection-2.14.0 /kaggle/working/mmdetection\n%cd /kaggle/working/mmdetection\n!pip install -e . --no-deps\n%cd /kaggle/working/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2021-08-13T02:18:16.089669Z","iopub.execute_input":"2021-08-13T02:18:16.090066Z","iopub.status.idle":"2021-08-13T02:18:16.128652Z","shell.execute_reply.started":"2021-08-13T02:18:16.089975Z","shell.execute_reply":"2021-08-13T02:18:16.127917Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# 아래를 수행하기 전에 kernel을 restart 해야 함. \nfrom mmdet.apis import init_detector, inference_detector\nimport mmcv","metadata":{"id":"kNPWIavsNLiU","execution":{"iopub.status.busy":"2021-08-09T13:19:23.715167Z","iopub.execute_input":"2021-08-09T13:19:23.715646Z","iopub.status.idle":"2021-08-09T13:19:40.135508Z","shell.execute_reply.started":"2021-08-09T13:19:23.715572Z","shell.execute_reply":"2021-08-09T13:19:40.134583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 간략히 이미지 먼저 보기","metadata":{}},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport cv2\n\nimg = cv2.cvtColor(cv2.imread('/kaggle/input/siim-covid19-resized-to-512px-png/train/000a312787f2.png'), cv2.COLOR_BGR2RGB)\nplt.figure(figsize=(3, 3))\nplt.imshow(img)","metadata":{"id":"WzvmxaXQNTum","executionInfo":{"status":"ok","timestamp":1622076509755,"user_tz":-540,"elapsed":2557,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"1ceb5edf-9bfe-48fa-ea76-653fcc1f1c49","execution":{"iopub.status.busy":"2021-08-09T13:19:49.685079Z","iopub.execute_input":"2021-08-09T13:19:49.685447Z","iopub.status.idle":"2021-08-09T13:19:49.93926Z","shell.execute_reply.started":"2021-08-09T13:19:49.68541Z","shell.execute_reply":"2021-08-09T13:19:49.938409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### COVID Dataset","metadata":{"id":"ZBdOvUOfVN8U"}},{"cell_type":"code","source":"# 우리 클래스는 opacity 한 클래스임. - 간략한 예시 코드\nCLASSES = ('opacity',)\nopacity2label = {k:i for i, k in enumerate(CLASSES)}\nprint(opacity2label)\nopacity2label['opacity']\n","metadata":{"id":"YAUEpbYSUfOO","executionInfo":{"status":"ok","timestamp":1622076521711,"user_tz":-540,"elapsed":512,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"7f4fbd5b-159d-43ec-f3ac-5af3be2a64dd","execution":{"iopub.status.busy":"2021-08-09T13:19:54.485796Z","iopub.execute_input":"2021-08-09T13:19:54.486149Z","iopub.status.idle":"2021-08-09T13:19:54.493595Z","shell.execute_reply.started":"2021-08-09T13:19:54.486116Z","shell.execute_reply":"2021-08-09T13:19:54.492507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npd.read_csv('/kaggle/input/all-ann-meta/train_meta.csv').tail()","metadata":{"id":"GyRjJQBl48cM","executionInfo":{"status":"ok","timestamp":1622076526551,"user_tz":-540,"elapsed":577,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"171f87e0-6679-4752-f17e-9160a5f87bc5","execution":{"iopub.status.busy":"2021-08-09T13:19:55.90365Z","iopub.execute_input":"2021-08-09T13:19:55.90401Z","iopub.status.idle":"2021-08-09T13:19:56.005267Z","shell.execute_reply.started":"2021-08-09T13:19:55.903976Z","shell.execute_reply":"2021-08-09T13:19:56.004437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 512\n\ndef get_bbox(row):\n    bboxes = []\n    bbox = []\n    for i, l in enumerate(row.label.split(' ')):\n        if (i % 6 == 0) | (i % 6 == 1):\n            continue\n        bbox.append(float(l))\n        if i % 6 == 5:\n            bboxes.append(bbox)\n            bbox = []  \n            \n    return bboxes\n\n# Scale the bounding boxes according to the size of the resized image. \ndef scale_bbox(row, bboxes):\n    # Get scaling factor\n    scale_x = IMG_SIZE/row.dim1\n    scale_y = IMG_SIZE/row.dim0\n    \n    scaled_bboxes = []\n    for bbox in bboxes:\n        x = int(np.round(bbox[0]*scale_x, 4))\n        y = int(np.round(bbox[1]*scale_y, 4))\n        x1 = int(np.round(bbox[2]*(scale_x), 4))\n        y1= int(np.round(bbox[3]*scale_y, 4))\n\n        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n        \n    return scaled_bboxes\n","metadata":{"execution":{"iopub.status.busy":"2021-08-09T13:19:58.815051Z","iopub.execute_input":"2021-08-09T13:19:58.815412Z","iopub.status.idle":"2021-08-09T13:19:58.823504Z","shell.execute_reply.started":"2021-08-09T13:19:58.815379Z","shell.execute_reply":"2021-08-09T13:19:58.822616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\nimport os.path as osp\nimport cv2\n\nimport mmcv\nimport numpy as np\n\nfrom mmdet.datasets.builder import DATASETS\nfrom mmdet.datasets.custom import CustomDataset\n\n@DATASETS.register_module(force=True)\nclass CovidDataset(CustomDataset):\n    CLASSES = ('opacity',)\n    def load_annotations(self, ann_file):\n        print('##### self.data_root:', self.data_root, 'self.ann_file:', self.ann_file, 'self.img_prefix:', self.img_prefix)\n        print('#### ann_file:', ann_file)\n        opacity2label = {k:i for i, k in enumerate(self.CLASSES)}\n\n        df = pd.read_csv(self.ann_file) # ann_file = all-ann-meta/total_meta.csv # data_root = /kaggle/input/\n#         image_list = list(ann.image_id)\n\n        data_infos = []\n        \n        for i in range(len(df)):\n            row = df.loc[i]\n            image_id = row.image_id\n            train_val = row.train_val\n            label = row.label\n            \n            if label != 'none 1 0 0 1 1':\n                filename = '{0:}/{1:}.png'.format(self.img_prefix, image_id) \n                image = cv2.imread(filename)\n                height, width = image.shape[:2]\n                data_info = {'filename': str(image_id) + '.png',\n                           'width': width, 'height': height} # 어차피 512\n        \n            \n                bboxes = get_bbox(row)\n                scale_bboxes = scale_bbox(row, bboxes)\n                \n                gt_bboxes = []\n                gt_labels = []\n                gt_bboxes_ignore = []\n                gt_labels_ignore = []\n                \n                for bbox in scale_bboxes:\n                    bbox_name = 'opacity'\n                    gt_bboxes.append(bbox)\n                    gt_labels.append(opacity2label[bbox_name])     \n                    \n                    data_anno = {\n                      'bboxes': np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n                      'labels': np.array(gt_labels, dtype=np.long),\n                      'bboxes_ignore': np.array(gt_bboxes_ignore, dtype=np.float32).reshape(-1, 4),\n                      'labels_ignore': np.array(gt_labels_ignore, dtype=np.long)\n                    }\n                \n               \n                data_info.update(ann=data_anno)\n                data_infos.append(data_info)\n        return data_infos","metadata":{"id":"-9LF0FKWO3rF","execution":{"iopub.status.busy":"2021-08-09T13:19:59.383541Z","iopub.execute_input":"2021-08-09T13:19:59.383897Z","iopub.status.idle":"2021-08-09T13:19:59.397378Z","shell.execute_reply.started":"2021-08-09T13:19:59.383864Z","shell.execute_reply":"2021-08-09T13:19:59.395983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport copy\nimport os.path as osp\nimport cv2\n\nimport mmcv\nimport numpy as np\n\nfrom mmdet.datasets.builder import DATASETS\nfrom mmdet.datasets.custom import CustomDataset\n\n@DATASETS.register_module(force=True)\nclass CovidDataset_debug(CustomDataset):\n    CLASSES = ('opacity',)\n    \n    def __init__(self, data_root, ann_file, img_prefix):\n        self.data_root = data_root\n        self.ann_file = osp.join(data_root, ann_file)\n        self.img_prefix = osp.join(data_root, img_prefix)\n        self.data_infos = self.load_annotations(self.ann_file)\n\n    def load_annotations(self, ann_file):\n        print('##### self.data_root:', self.data_root, 'self.ann_file:', self.ann_file, 'self.img_prefix:', self.img_prefix)\n        print('#### ann_file:', ann_file)\n        opacity2label = {k:i for i, k in enumerate(self.CLASSES)}\n        df = pd.read_csv(self.ann_file)\n        data_infos = []\n        \n        for i in range(len(df)):\n            row = df.loc[i]\n            image_id = row.image_id\n            train_val = row.train_val\n            label = row.label\n            \n            if label != 'none 1 0 0 1 1':\n                \n                filename = '{0:}/{1:}.png'.format(self.img_prefix, image_id) \n                image = cv2.imread(filename)\n                height, width = image.shape[:2]\n                data_info = {'filename': str(image_id) + '.png',\n                           'width': width, 'height': height} # 어차피 512\n        \n            \n                bboxes = get_bbox(row)\n                scale_bboxes = scale_bbox(row, bboxes)\n                \n                gt_bboxes = []\n                gt_labels = []\n                gt_bboxes_ignore = []\n                gt_labels_ignore = []\n                \n                for bbox in scale_bboxes:\n                    bbox_name = 'opacity'\n                    gt_bboxes.append(bbox)\n                    gt_labels.append(opacity2label[bbox_name])     \n                    \n                    data_anno = {\n                      'bboxes': np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n                      'labels': np.array(gt_labels, dtype=np.long),\n                      'bboxes_ignore': np.array(gt_bboxes_ignore, dtype=np.float32).reshape(-1, 4),\n                      'labels_ignore': np.array(gt_labels_ignore, dtype=np.long)\n                    }\n            \n                data_info.update(ann=data_anno)\n                data_infos.append(data_info)\n        return data_infos","metadata":{"execution":{"iopub.status.busy":"2021-08-09T13:20:01.656045Z","iopub.execute_input":"2021-08-09T13:20:01.656378Z","iopub.status.idle":"2021-08-09T13:20:01.673604Z","shell.execute_reply.started":"2021-08-09T13:20:01.656346Z","shell.execute_reply":"2021-08-09T13:20:01.672416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 디버깅 용\ntrain_ds = CovidDataset_deb(data_root='/kaggle/input', ann_file='all-ann-meta/train_meta.csv', img_prefix='siim-covid19-resized-to-512px-png/train')\nprint(train_ds.data_infos[:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 해당 Config 파일 지정, 및  다운로드된 Pretrained 모델\nconfig_file = '/kaggle/working/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\ncheckpoint_file = '/kaggle/working/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'","metadata":{"id":"OAm8tH0GKWwf","execution":{"iopub.status.busy":"2021-08-09T13:20:07.22536Z","iopub.execute_input":"2021-08-09T13:20:07.22579Z","iopub.status.idle":"2021-08-09T13:20:07.229912Z","shell.execute_reply.started":"2021-08-09T13:20:07.225752Z","shell.execute_reply":"2021-08-09T13:20:07.228882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmcv import Config\n\ncfg = Config.fromfile(config_file)\nprint(cfg.pretty_text)","metadata":{"id":"mc-TPyQkfIwk","executionInfo":{"status":"ok","timestamp":1622078772506,"user_tz":-540,"elapsed":1276,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"f079c80a-8c49-4b5a-8f8f-31542e434dff","execution":{"iopub.status.busy":"2021-08-09T13:20:12.15087Z","iopub.execute_input":"2021-08-09T13:20:12.151255Z","iopub.status.idle":"2021-08-09T13:20:12.567828Z","shell.execute_reply.started":"2021-08-09T13:20:12.15122Z","shell.execute_reply":"2021-08-09T13:20:12.566622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmdet.apis import set_random_seed\n\n# dataset에 대한 환경 파라미터 수정. \ncfg.dataset_type = 'CovidDataset'\ncfg.data_root = '/kaggle/input/'\n\n# train, val, test dataset에 대한 type, data_root, ann_file, img_prefix 환경 파라미터 수정. \ncfg.data.train.type = 'CovidDataset'\ncfg.data.train.data_root = '/kaggle/input/'\ncfg.data.train.ann_file = 'all-ann-meta/train_meta.csv'\ncfg.data.train.img_prefix = 'siim-covid19-resized-to-512px-png/train'\n\ncfg.data.val.type = 'CovidDataset'\ncfg.data.val.data_root = '/kaggle/input/'\ncfg.data.val.ann_file = 'all-ann-meta/val_meta.csv'\ncfg.data.val.img_prefix = 'siim-covid19-resized-to-512px-png/train'\n\ncfg.data.test.type = 'CovidDataset'\ncfg.data.test.data_root = '/kaggle/input/'\ncfg.data.test.ann_file = 'all-ann-meta/val_meta.csv'\ncfg.data.test.img_prefix = 'siim-covid19-resized-to-512px-png/train'\n\n# class 수 \ncfg.model.roi_head.bbox_head.num_classes = 1\n# pretrained 모델\ncfg.load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n\n# 학습 weight 파일로 로그를 저장하기 위한 디렉토리 설정. \ncfg.work_dir = '/kaggle/input'\n\n# 학습율 변경 환경 파라미터 설정. \ncfg.optimizer.lr = 0.02 / 8\n\ncfg.lr_config.warmup = None\ncfg.log_config.interval = 10\n\ncfg.runner.max_epochs = 15           # ep 5번만 돌겠다. # schedule 참고 기본 12\n# config 수행 시마다 policy값이 없어지는 bug로 인하여 설정. \ncfg.lr_config.policy = 'step'\n\n# Change the evaluation metric since we use customized dataset.\ncfg.evaluation.metric = 'mAP'\n# We can set the evaluation interval to reduce the evaluation times\ncfg.evaluation.interval = 1\n# We can set the checkpoint saving interval to reduce the storage cost\ncfg.checkpoint_config.interval = 1\n\n# Set seed thus the results are more reproducible\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\n\n# 학습 시 Batch size 설정(단일 GPU 별 Batch size로 설정됨)    # 이게 배치사이즈 설정!\n# cfg.data.samples_per_gpu = 4        # gpu가 2개면 bsize는 자동으로 8개가 되겠다. 근데 여기선 gpu T4 1개...\n\n# 총 3300개 정도 train이미지를 학습할때, bsize=4이면 4장 이미지 가져와 4장마다 loss구해가면서 대략 800번 iteration돌아\n# batch size 클수록 학습속도가 빠르다 : 여러 이미지를 한번에 학습하여 loss를 구하니까\n# 그러나, batch size크면 gpu memory가 커져 죽을 수 있다...\n\n\n# We can initialize the logger for training and have a look\n# at the final config used for training\nprint(f'Config:\\n{cfg.pretty_text}')","metadata":{"id":"l6DnkHuvl5WY","executionInfo":{"status":"ok","timestamp":1622091874979,"user_tz":-540,"elapsed":1408,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"9789ca19-543c-4120-919e-e3967485495d","execution":{"iopub.status.busy":"2021-08-09T14:04:54.095955Z","iopub.execute_input":"2021-08-09T14:04:54.096317Z","iopub.status.idle":"2021-08-09T14:04:54.400751Z","shell.execute_reply.started":"2021-08-09T14:04:54.096278Z","shell.execute_reply":"2021-08-09T14:04:54.399849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Config에서 설정한 Dataset, Model, Pipeline 등에 따라 모델 학습 수행. \n\n* train용 Dataset을 생성하고 이를 이용하여 학습 수행. ","metadata":{"id":"zIgw7CSOqUxS"}},{"cell_type":"code","source":"from mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\n\n# train용 Dataset 생성. \ndatasets = [build_dataset(cfg.data.train)]","metadata":{"id":"OhYoe1KSk5dC","executionInfo":{"status":"ok","timestamp":1622080678995,"user_tz":-540,"elapsed":508,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"d867319b-8303-49ac-d264-a690436f5680","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets[0].CLASSES","metadata":{"id":"c8D4Q1CfjNoY","executionInfo":{"status":"ok","timestamp":1622080808215,"user_tz":-540,"elapsed":407,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"8e782039-85fc-4b57-f6d6-22816c0ba323","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES","metadata":{"id":"PQZbvPJxss-w","executionInfo":{"status":"ok","timestamp":1622080796148,"user_tz":-540,"elapsed":1341,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"9e70f95b-a44a-46ca-a384-a10ab76ac599","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 주의, config에 pretrained 모델 지정이 상대 경로로 설정됨 cfg.load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n# 아래와 같이 %cd mmdetection 지정 필요. \n \n%cd mmdetection \n\nmmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n\n# epochs는 config의 runner 파라미터로 지정됨. 기본 12회 \ntrain_detector(model, datasets, cfg, distributed=False, validate=True)","metadata":{"id":"ccn2TffRnpu1","executionInfo":{"status":"ok","timestamp":1622080970037,"user_tz":-540,"elapsed":112567,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"899e87be-e909-409d-b7ca-44df5fd2260e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls /kaggle/working/mmdetection/tutorial_exps/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cp /kaggle/working/mmdetection/tutorial_exps/epoch_10.pth /kaggle/working\n# !cp /kaggle/working/mmdetection/tutorial_exps/epoch_20.pth /kaggle/working\n# !cp /kaggle/working/mmdetection/tutorial_exps/epoch_30.pth /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 학습된 model 로드하여 inference 수행. ","metadata":{"id":"lRjzWDXYzqdw"}},{"cell_type":"code","source":"cfg.model.test_cfg.rcnn.score_thr = 0.001\n\nWEIGHTS_FILE = '/kaggle/input/model-faster-rcnn/epoch_10.pth'\noptions = dict(classes = (\"Covid_Abnormality\"))\nmodel = init_detector(cfg, WEIGHTS_FILE, device='cuda:0')","metadata":{"execution":{"iopub.status.busy":"2021-08-09T13:20:38.889148Z","iopub.execute_input":"2021-08-09T13:20:38.889512Z","iopub.status.idle":"2021-08-09T13:20:51.052135Z","shell.execute_reply.started":"2021-08-09T13:20:38.889462Z","shell.execute_reply":"2021-08-09T13:20:51.051102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n\n# BGR Image 사용 \nimg = cv2.imread('/kaggle/input/siim-covid19-resized-to-512px-png/train/000a312787f2.png')\n\nmodel.cfg = cfg\n\nresult = inference_detector(model, img)\nshow_result_pyplot(model, img, result)","metadata":{"id":"ihB1s7N-wT9g","executionInfo":{"status":"ok","timestamp":1622081213947,"user_tz":-540,"elapsed":3312,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"c1064957-1e5d-4a7a-a378-adbcdebd6e9c","execution":{"iopub.status.busy":"2021-08-09T13:21:16.506012Z","iopub.execute_input":"2021-08-09T13:21:16.506419Z","iopub.status.idle":"2021-08-09T13:21:16.937947Z","shell.execute_reply.started":"2021-08-09T13:21:16.506381Z","shell.execute_reply":"2021-08-09T13:21:16.934805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.data.test","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:05:34.644278Z","iopub.execute_input":"2021-08-09T14:05:34.644673Z","iopub.status.idle":"2021-08-09T14:05:34.653386Z","shell.execute_reply.started":"2021-08-09T14:05:34.644632Z","shell.execute_reply":"2021-08-09T14:05:34.652567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmdet.datasets import build_dataloader, build_dataset, replace_ImageToTensor\n\n\n# test용 Dataset과 DataLoader 생성. \n# build_dataset()호출 시 list로 감싸지 않는 것이 train용 dataset 생성시와 차이. \n\ncfg.data.samples_per_gpu = 1 \n\ndataset = build_dataset(cfg.data.val)\ndata_loader = build_dataloader(\n        dataset,\n        # 반드시 아래 samples_per_gpu 인자값은 1로 설정\n        samples_per_gpu=cfg.data.samples_per_gpu,\n        workers_per_gpu=cfg.data.workers_per_gpu,\n        dist=False,\n        shuffle=False)\n\n# 반드시 아래 코드에서 'img' 키값이 tensor로 출력되어야 함. \n# next(iter(data_loader))\n\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot\nfrom mmdet.apis import multi_gpu_test, single_gpu_test\nfrom mmcv.parallel import MMDataParallel, MMDistributedDataParallel\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot\n\n\ncheckpoint_file = '../input/model-faster-rcnn/epoch_10.pth'\n\n# checkpoint 저장된 model 파일을 이용하여 모델을 생성, 이때 Config는 위에서 update된 config 사용. \nmodel_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')\n\n\nmodel_ckpt = MMDataParallel(model_ckpt, device_ids=[0])\n# single_gpu_test() 를 호출하여 test데이터 세트의 interence 수행. 반드시 batch size는 1이 되어야 함. \n# 위에서 만든 /content/show_test_output 디렉토리에 interence 결과가 시각화된 이미지가 저장됨. \noutputs = single_gpu_test(model_ckpt, data_loader, False)\n\nmetric = dataset.evaluate(outputs, metric='mAP')\nprint(metric)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:06:39.264259Z","iopub.execute_input":"2021-08-09T14:06:39.264684Z","iopub.status.idle":"2021-08-09T14:06:42.204826Z","shell.execute_reply.started":"2021-08-09T14:06:39.264654Z","shell.execute_reply":"2021-08-09T14:06:42.203574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-09T14:06:51.28941Z","iopub.execute_input":"2021-08-09T14:06:51.289779Z","iopub.status.idle":"2021-08-09T14:06:52.184176Z","shell.execute_reply.started":"2021-08-09T14:06:51.289744Z","shell.execute_reply":"2021-08-09T14:06:52.183268Z"},"trusted":true},"execution_count":null,"outputs":[]}]}